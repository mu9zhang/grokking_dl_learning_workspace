{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Delta: -0.1399999999999999\n",
      "Weights: [0.1119, 0.20091, -0.09832]\n",
      "Weight Deltas: [-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gradient Descent aslo Works with Multiple Inputs\n",
    "\"\"\"\n",
    "\n",
    "# 1. A network with multiple inputs\n",
    "def w_sum(a, b):\n",
    "    assert(len(a) == len(b))\n",
    "    output = 0\n",
    "    for i in range(len(a)):\n",
    "        output += (a[i] * b[i])\n",
    "    return output\n",
    "\n",
    "\n",
    "weights = [0.1, 0.2, -.1]\n",
    "def neural_network(input, weights):\n",
    "    pred = w_sum(input, weights)\n",
    "    return pred\n",
    "\n",
    "\n",
    "# 2. Data\n",
    "toes  = [8.5 , 9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2 , 1.3, 0.5, 1.0]\n",
    "win_or_lose_binary = [1, 1, 0, 1]\n",
    "\n",
    "true = win_or_lose_binary[0]\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "\n",
    "\n",
    "# 3. Predict & Evaluate\n",
    "pred = neural_network(input, weights)\n",
    "error = (pred - true) ** 2\n",
    "delta = pred - true\n",
    "\n",
    "\n",
    "# 4. Learning\n",
    "def ele_mul(number, vector):\n",
    "    output = [0, 0, 0]\n",
    "    assert(len(output) == len(vector))\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = number * vector[i]\n",
    "    return output\n",
    "\n",
    "# The three weights share the same output node, they also share that node’s delta. \n",
    "# But the weights have different weight deltas owing to their different input values.\n",
    "weight_deltas = ele_mul(delta, input)\n",
    "\n",
    "\n",
    "# 5. Updating\n",
    "alpha = 0.01\n",
    "\n",
    "for i in range(len(weights)):\n",
    "    weights[i] -= alpha * weight_deltas[i]\n",
    "print(\"Delta: \" + str(delta))\n",
    "print(\"Weights: \" + str(weights))\n",
    "print(\"Weight Deltas: \" + str(weight_deltas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:1\n",
      "Pred:0.8600000000000001\n",
      "Error:0.01959999999999997\n",
      "Delta:-0.1399999999999999\n",
      "Weights:[0.1, 0.2, -0.1]\n",
      "Weight_Deltas:\n",
      "[-1.189999999999999, -0.09099999999999994, -0.16799999999999987]\n",
      "\n",
      "Iteration:2\n",
      "Pred:0.9637574999999999\n",
      "Error:0.0013135188062500048\n",
      "Delta:-0.036242500000000066\n",
      "Weights:[0.1119, 0.20091, -0.09832]\n",
      "Weight_Deltas:\n",
      "[-0.30806125000000056, -0.023557625000000044, -0.04349100000000008]\n",
      "\n",
      "Iteration:3\n",
      "Pred:0.9906177228125002\n",
      "Error:8.802712522307997e-05\n",
      "Delta:-0.009382277187499843\n",
      "Weights:[0.11498061250000001, 0.20114557625, -0.09788509000000001]\n",
      "Weight_Deltas:\n",
      "[-0.07974935609374867, -0.006098480171874899, -0.011258732624999811]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Watch the several steps of learning\n",
    "\n",
    "1. delta is a measure of how much you want a node’s value to be different. weight_delta, on the other hand, is an estimate of the direction\n",
    "   and amount to move the weights to reduce node_delta, inferred by the derivative. How do you transform delta into a weight_delta? You\n",
    "   multiply delta by a weight’s input. Thus, weight_delta is a sort of input-modified version of delta.\n",
    "\n",
    "2. In multi-input version of neural network, each weight has a unique input and a shared delta, you use each respective weight’s input\n",
    "   multiplied by delta to create each respective weight_delta, and then use it to update each respective weight.\n",
    "   \n",
    "3. Here are a few additional takeaways. Most of the learning (weight changing) was performed on the weight with the largest input a , because\n",
    "   the input changes the slope significantly. This isn’t necessarily advantageous in all settings. A subfield called normalization helps\n",
    "   encourage learning across all weights despite dataset characteristics such as this. \n",
    "\"\"\"\n",
    "\n",
    "weights = [0.1, 0.2, -.1]\n",
    "alpha = 0.01\n",
    "\n",
    "for iter in range(3):\n",
    "    pred  = neural_network(input, weights)\n",
    "    error = (pred - true) ** 2\n",
    "    delta = pred - true\n",
    "    weight_deltas = ele_mul(delta, input)\n",
    "    \n",
    "    print(\"Iteration:\" + str(iter+1))\n",
    "    print(\"Pred:\" + str(pred))\n",
    "    print(\"Error:\" + str(error))\n",
    "    print(\"Delta:\" + str(delta))\n",
    "    print(\"Weights:\" + str(weights))\n",
    "    print(\"Weight_Deltas:\")\n",
    "    print(str(weight_deltas))\n",
    "    print()\n",
    "    \n",
    "    # Most of the learning (weight changing) was performed on the weight with the largest input\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= alpha * weight_deltas[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:1\n",
      "Pred:0.8600000000000001\n",
      "Error:0.01959999999999997\n",
      "Delta:-0.1399999999999999\n",
      "Weights:[0.1, 0.2, -0.1]\n",
      "Weight_Deltas:\n",
      "[0, -0.09099999999999994, -0.16799999999999987]\n",
      "\n",
      "Iteration:2\n",
      "Pred:0.9382250000000001\n",
      "Error:0.003816150624999989\n",
      "Delta:-0.06177499999999991\n",
      "Weights:[0.1, 0.2273, -0.04960000000000005]\n",
      "Weight_Deltas:\n",
      "[0, -0.040153749999999946, -0.07412999999999989]\n",
      "\n",
      "Iteration:3\n",
      "Pred:0.97274178125\n",
      "Error:0.000743010489422852\n",
      "Delta:-0.027258218750000007\n",
      "Weights:[0.1, 0.239346125, -0.02736100000000008]\n",
      "Weight_Deltas:\n",
      "[0, -0.017717842187500006, -0.032709862500000006]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Freezing One Weight: Leave fist weight unchanged\n",
    "\n",
    "1. This reveals a potentially damaging property of neural networks: 1st weight may be a powerful input with lots of predictive power,\n",
    "   but if the network accidentally figures out how to predict accurately on the training data without it, then it will never learn to\n",
    "   incorporate a into its prediction. \n",
    "\n",
    "2. Also notice how 1st weight finds the bottom of the bowl. Instead of the black dot moving, the curve seems to move to the left. What does\n",
    "   this mean? The black dot can move horizontally only if the weight is updated. Because the weight for 1st is frozen for this experiment,\n",
    "   the dot must stay fixed. But error clearly goes to 0.\n",
    "\n",
    "3. The error is determined by the training data. Any network can have any weight value, but the value of error given any particular weight\n",
    "   configuration is 100% determined by data. You’ve already seen how the steepness of the U shape is affected by the input data. What\n",
    "   you’re really trying to do with the neural network is find the lowest point on this big error plane, where the lowest point refers to\n",
    "   the lowest error. \n",
    "\"\"\"\n",
    "\n",
    "weights = [0.1, 0.2, -.1]\n",
    "alpha = 0.3\n",
    "\n",
    "for iter in range(3):\n",
    "    pred  = neural_network(input, weights)\n",
    "    error = (pred - true) ** 2\n",
    "    delta = pred - true\n",
    "    weight_deltas = ele_mul(delta, input)\n",
    "    weight_deltas[0] = 0\n",
    "    \n",
    "    print(\"Iteration:\" + str(iter+1))\n",
    "    print(\"Pred:\" + str(pred))\n",
    "    print(\"Error:\" + str(error))\n",
    "    print(\"Delta:\" + str(delta))\n",
    "    print(\"Weights:\" + str(weights))\n",
    "    print(\"Weight_Deltas:\")\n",
    "    print(str(weight_deltas))\n",
    "    print()\n",
    "\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] -= alpha * weight_deltas[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:[0.281475, 0.36965000000000003, 0.8054250000000001]\n",
      "Weight Deltas:[0.061750000000000006, -0.5655, 0.3152500000000001]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gradient Descent Learning with One Input and Multiple Outputs\n",
    "\"\"\"\n",
    "\n",
    "# 1. A network with multiple outputs\n",
    "weights = [0.3, 0.2, 0.9]\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = ele_mul(input, weights)\n",
    "    return pred\n",
    "\n",
    "\n",
    "# 2. Predict and calcuate error and delta\n",
    "wlrec = [0.65, 1.0, 1.0, 0.9] # input\n",
    "\n",
    "hurt  = [0.1, 0.0, 0.0, 0.1]  # output (label)\n",
    "win  =  [1,   1,   0,   1]\n",
    "sad =   [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "input = wlrec[0]\n",
    "true = [hurt[0], win[0], sad[0]]\n",
    "pred = neural_network(input, weights)\n",
    "\n",
    "error = [0, 0, 0]\n",
    "delta = [0, 0, 0]\n",
    "for i in range(len(true)):\n",
    "    error[i] = (pred[i] - true[i]) ** 2\n",
    "    delta[i] =  pred[i] - true[i]\n",
    "\n",
    "\n",
    "# 3. Compare\n",
    "def scalar_ele_mul(number, vector):\n",
    "    output = [0, 0, 0]\n",
    "    assert(len(output) == len(vector))\n",
    "    for i in range(len(vector)):\n",
    "        output[i] = number * vector[i]\n",
    "    return output\n",
    "\n",
    "# You calculate each delta the same way and then multiply them all by the same, single input. (Delta of each input is different)\n",
    "# This becomes each weight’s weight_delta. \n",
    "weight_deltas = scalar_ele_mul(input,delta)\n",
    "\n",
    "\n",
    "# 4. Learning\n",
    "for i in range(len(weights)):\n",
    "    weights[i] -= (weight_deltas[i] * alpha)\n",
    "\n",
    "print(\"Weights:\" + str(weights))\n",
    "print(\"Weight Deltas:\" + str(weight_deltas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.5, 0.65, 1.2]\n",
      "[0.45500000000000007, -0.019999999999999907, 0.8650000000000001]\n",
      "Weights:[[0.061325, 0.1017, -0.373525], [0.0970425, 0.20013, -0.005622500000000002], [-0.0054600000000000004, 1.30024, 0.08962]]\n",
      "Weight Deltas:[[3.8675000000000006, -0.1699999999999992, 7.352500000000001], [0.29575000000000007, -0.01299999999999994, 0.5622500000000001], [0.546, -0.023999999999999886, 1.038]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Gradient Descent Learning with Multiple Inputs and Multiple Outputs\n",
    "\"\"\"\n",
    "\n",
    "# 1. A network with multiple inputs and outputs\n",
    "weights = [ [0.1, 0.1, -0.3],\n",
    "            [0.1, 0.2,  0.0],\n",
    "            [0.0, 1.3,  0.1]]\n",
    "\n",
    "def vect_mat_mul(vect, matrix):\n",
    "    assert(len(vect) == len(matrix))\n",
    "    output = [0, 0, 0]\n",
    "    for i in range(len(vect)):\n",
    "        output[i] += w_sum(vect, matrix[i])\n",
    "    return output\n",
    "\n",
    "def neural_network(input, weights):\n",
    "    pred = vect_mat_mul(input, weights)\n",
    "    return pred\n",
    "\n",
    "# 2. Predict\n",
    "toes  = [8.5,  9.5, 9.9, 9.0]\n",
    "wlrec = [0.65, 0.8, 0.8, 0.9]\n",
    "nfans = [1.2,  1.3, 0.5, 1.0]\n",
    "\n",
    "hurt = [0.1, 0.0, 0.0, 0.1]\n",
    "win  = [ 1,  1,   0,   1]\n",
    "sad  = [0.1, 0.0, 0.1, 0.2]\n",
    "\n",
    "alpha = 0.01\n",
    "input = [toes[0], wlrec[0], nfans[0]]\n",
    "true  = [hurt[0], win[0],   sad[0]]\n",
    "\n",
    "pred = neural_network(input,weights)\n",
    "\n",
    "error = [0, 0, 0]\n",
    "delta = [0, 0, 0]\n",
    "\n",
    "for i in range(len(true)):\n",
    "    error[i] = (pred[i] - true[i]) ** 2\n",
    "    delta[i] = pred[i] - true[i]\n",
    "\n",
    "# 3. Compare\n",
    "def zeros_matrix(len_a, len_b):\n",
    "    z_mat = []\n",
    "    for i in range(len_a):\n",
    "        mat = []\n",
    "        for j in range(len_b):\n",
    "            mat.append(0)\n",
    "        z_mat.append(mat)\n",
    "    return z_mat\n",
    "\n",
    "def outer_prod(vec_a, vec_b):\n",
    "    out = zeros_matrix(len(vec_a), len(vec_b))\n",
    "    for i in range(len(vec_a)):\n",
    "        for j in range(len(vec_b)):\n",
    "            out[i][j] = vec_a[i] * vec_b[j]   # 外积： 3×1 vector * 1×3 vector = 3 × 3 matrix\n",
    "    return out\n",
    "\n",
    "print(input)\n",
    "print(delta)\n",
    "weight_deltas = outer_prod(input, delta)\n",
    "\n",
    "# 4. Learn\n",
    "for i in range(len(weights)):\n",
    "    for j in range(len(weights[0])):\n",
    "        weights[i][j] -= alpha * weight_deltas[i][j]\n",
    "print(\"Weights:\" + str(weights))\n",
    "print(\"Weight Deltas:\" + str(weight_deltas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Other Notes:\n",
    "\n",
    "1. If the weight is high, it means the model believes there’s a high degree of correlation between that pixel and the number 2. If the\n",
    "   number is very low (negative), then the network believes there is a very low correlation (perhaps even negative correlation) between that\n",
    "   pixel and the number 2. \n",
    "\n",
    "2. A dot product is a loose measurement of similarity between two vectors. What does this mean for the weights and inputs? Well, if the\n",
    "   weight vector is similar to the input vector for 2, then it will output a high score because the two vectors are similar. Inversely, if\n",
    "   the weight vector is not similar to the input vector for 2, it will output a low score.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
